{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import momepy as mm\n",
    "from tqdm import tqdm\n",
    "from shapely.wkt import loads\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from osgeo import ogr\n",
    "import shapely\n",
    "\n",
    "import time\n",
    "\n",
    "# input\n",
    "network = gpd.read_file(\n",
    "    'files/AMS/tempnet.gpkg', layer='tempnet'\n",
    ")\n",
    "# network = network.loc[network.type.isin(['LineString', 'MultiLineString'])]\n",
    "# network_cleaned = mm.network_false_nodes(network_cl)\n",
    "# network_cleaned['uID'] = range(len(network_cleaned))\n",
    "# network = network_cleaned\n",
    "# network = network.loc[~network.NFC.isin(['Interstate', 'Other Freeway'])]\n",
    "buildings = gpd.read_file('files/AMS/elements.gpkg', layer='buildings')\n",
    "\n",
    "network.crs == buildings.crs\n",
    "\n",
    "start = time.time()\n",
    "# parameters\n",
    "max_size = 100000\n",
    "size = 5000\n",
    "circom_min = 0.2\n",
    "circom_max = 0.75\n",
    "selfsnap_tolerance = 5\n",
    "bowtie_tolerance = 0.4\n",
    "\n",
    "\n",
    "#########\n",
    "def _remove_leading_out(input, context, tolerance=0.25):\n",
    "    \"\"\"\n",
    "    context defines if it leads somewhere\n",
    "\n",
    "    TODO: use rtree to speed up intersections\n",
    "    \"\"\"\n",
    "    to_remove = []\n",
    "    for i, ls in input.iteritems():\n",
    "        first = Point(ls.coords[0]).buffer(tolerance)\n",
    "        last = Point(ls.coords[-1]).buffer(tolerance)\n",
    "        remove = False\n",
    "        for p in [first, last]:\n",
    "            if not input.drop(i).intersects(p).any() and not context.intersects(p).any():\n",
    "                remove = True\n",
    "        if remove:\n",
    "            to_remove.append(i)\n",
    "    return input.drop(to_remove)\n",
    "\n",
    "\n",
    "def _snap(input, target, tolerance, min=True):\n",
    "    \"\"\"\n",
    "    min True snaps to closest within tolerance, False to all within tolerance\n",
    "\n",
    "    TODO: use rtree to get distances only to relevant geoms\n",
    "    \"\"\"\n",
    "    input = input.copy()\n",
    "    for i, geom in input.iteritems():\n",
    "        distances = target.distance(geom)\n",
    "        if min:\n",
    "            close_geom = target.loc[distances.idxmin()]\n",
    "            geom = shapely.ops.snap(geom, close_geom, tolerance)\n",
    "        else:\n",
    "            close_geom = target.loc[distances < tolerance]\n",
    "            for p in close_geom:\n",
    "                geom = shapely.ops.snap(geom, p, tolerance)\n",
    "\n",
    "        input.loc[i] = geom\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "def _split(input, target, tolerance):\n",
    "    input = input.copy()\n",
    "    buf = target.buffer(tolerance)\n",
    "    for i, geom in input.iteritems():\n",
    "        intersects = target.loc[buf.intersects(geom)]\n",
    "        if not intersects.empty:\n",
    "            geom = shapely.ops.split(geom, intersects.unary_union)\n",
    "\n",
    "            input.loc[i] = geom\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "def _drop_duplicates(geoms):\n",
    "    mp = {}\n",
    "    for ix, geom in geoms.iteritems():\n",
    "        inters = geoms.intersection(geom).type == 'MultiPoint'\n",
    "\n",
    "        if inters.any():\n",
    "            mp[ix] = inters.loc[inters].index.to_list()[0]\n",
    "\n",
    "    drop = []\n",
    "    keep = []\n",
    "    for k in mp.keys():\n",
    "        if k not in keep:\n",
    "            drop.append(k)\n",
    "            keep.append(mp[k])\n",
    "\n",
    "    geoms = geoms.drop(drop)\n",
    "    return geoms\n",
    "\n",
    "\n",
    "def _get_snapping_centroids(input, tolerance):\n",
    "    \"\"\"\n",
    "    generate centroids from close-by points\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    for i, ls in input.iteritems():\n",
    "        first = Point(ls.coords[0])\n",
    "        last = Point(ls.coords[-1])\n",
    "        for p in [first, last]:\n",
    "            if input.drop(i).intersects(p.buffer(tolerance)).any():\n",
    "                points.append(p)\n",
    "    points = gpd.GeoSeries(points)\n",
    "    points = points.buffer(tolerance / 2)\n",
    "    union = points.unary_union\n",
    "    exploded = gpd.GeoSeries([union]).explode()\n",
    "    return exploded.centroid\n",
    "\n",
    "\n",
    "# polygonize network\n",
    "polygonized = shapely.ops.polygonize(network.geometry)\n",
    "geoms = [g for g in polygonized]\n",
    "gdf = gpd.GeoDataFrame(geometry=geoms, crs=network.crs)\n",
    "\n",
    "\n",
    "# calculate parameters\n",
    "gdf[\"area\"] = gdf.geometry.area\n",
    "gdf[\"circom\"] = mm.CircularCompactness(gdf, \"area\").series\n",
    "\n",
    "\n",
    "# select valid and invalid network-net_blocks\n",
    "possible = gdf.loc[gdf[\"area\"] < max_size]\n",
    "possible = possible.loc[\n",
    "    (possible[\"circom\"] > circom_max)\n",
    "    | (possible[\"circom\"] < circom_min)\n",
    "    | (possible[\"area\"] < size)\n",
    "]\n",
    "\n",
    "\n",
    "# check for buildings\n",
    "buildings[\"geometry\"] = buildings.geometry.representative_point()\n",
    "sindex = buildings.sindex\n",
    "\n",
    "drop = []\n",
    "for index, row in tqdm(possible.iterrows()):\n",
    "    possible_matches_index = list(sindex.intersection(row.geometry.bounds))\n",
    "    possible_matches = buildings.iloc[possible_matches_index]\n",
    "    if possible_matches.intersects(row.geometry).any():\n",
    "        drop.append(index)\n",
    "\n",
    "invalid = possible.drop(drop)\n",
    "\n",
    "\n",
    "# INSERTED - TO BE REMOVED\n",
    "invalid_manual = gpd.read_file('files/AMS/tempnet.gpkg', layer='invalid', )\n",
    "pts = invalid_manual.geometry.representative_point()\n",
    "trueinv = []\n",
    "for i, r in invalid.iterrows():\n",
    "    if pts.intersects(r.geometry).any():\n",
    "        trueinv.append(i)\n",
    "invalid = gdf[gdf.index.isin(trueinv)].copy()\n",
    "# UNTIL HERE\n",
    "\n",
    "valid = gdf[~gdf.index.isin(invalid.index)].copy()\n",
    "\n",
    "\n",
    "# select edges of valid as an input for tessellation\n",
    "# valid / network\n",
    "input = []\n",
    "sidx = network.sindex\n",
    "union = invalid.geometry.unary_union\n",
    "unioned = gpd.GeoSeries(union).explode().reset_index(drop=True)\n",
    "for i, r in tqdm(unioned.iteritems()):\n",
    "    possible_matches_index = list(sidx.intersection(r.bounds))\n",
    "    possible_matches = network.iloc[possible_matches_index]\n",
    "    real = network.intersection(r.exterior)\n",
    "    for ix, geom in real.geometry.iteritems():\n",
    "        input.append(geom)\n",
    "inter = gpd.GeoSeries(input)\n",
    "inters = inter[~(inter.is_empty | inter.isna())]\n",
    "geom_types = inters.type\n",
    "line_idx = np.asarray(\n",
    "    (geom_types == \"LineString\")\n",
    "    | (geom_types == \"MultiLineString\")\n",
    "    | (geom_types == \"LinearRing\")\n",
    ")\n",
    "intersections = inters[line_idx]\n",
    "\n",
    "\n",
    "# densify interesections ahead of tessellation\n",
    "def _densify(geom, segment):\n",
    "    \"\"\"\n",
    "    Returns densified geoemtry with segments no longer than `segment`.\n",
    "    \"\"\"\n",
    "    poly = geom\n",
    "    wkt = geom.wkt  # shapely Polygon to wkt\n",
    "    geom = ogr.CreateGeometryFromWkt(wkt)  # create ogr geometry\n",
    "    geom.Segmentize(segment)  # densify geometry by 2 metres\n",
    "    geom.CloseRings()  # fix for GDAL 2.4.1 bug\n",
    "    wkt2 = geom.ExportToWkt()  # ogr geometry to wkt\n",
    "    try:\n",
    "        new = loads(wkt2)  # wkt to shapely Polygon\n",
    "        return new\n",
    "    except Exception:\n",
    "        return poly\n",
    "\n",
    "\n",
    "dense = intersections.geometry.apply(_densify, segment=2)\n",
    "\n",
    "# generate point array for tessellation\n",
    "points = []\n",
    "ids = []\n",
    "for ix, r in dense.items():\n",
    "    if r.type == \"MultiLineString\":\n",
    "        for line in r:\n",
    "            point_coords = line.coords\n",
    "            row_array = np.array(point_coords[1:-1] if len(point_coords) > 2 else point_coords).tolist()\n",
    "            for i, a in enumerate(row_array):\n",
    "                points.append(row_array[i])\n",
    "                ids.append(ix)\n",
    "    elif r.type == \"LineString\":\n",
    "        point_coords = r.coords\n",
    "        row_array = np.array(point_coords[1:-1] if len(point_coords) > 2 else point_coords).tolist()\n",
    "        for i, a in enumerate(row_array):\n",
    "            points.append(row_array[i])\n",
    "            ids.append(ix)\n",
    "\n",
    "\n",
    "# generate tessellation\n",
    "voronoi_diagram = Voronoi(np.array(points))\n",
    "\n",
    "\n",
    "# generate regions\n",
    "def _regions(voronoi_diagram, unique_id, ids, crs):\n",
    "    \"\"\"\n",
    "    Generate GeoDataFrame of Voronoi regions from scipy.spatial.Voronoi.\n",
    "    \"\"\"\n",
    "    # generate DataFrame of results\n",
    "    regions = pd.DataFrame()\n",
    "    regions[unique_id] = ids  # add unique id\n",
    "    regions[\"region\"] = voronoi_diagram.point_region  # add region id for each point\n",
    "\n",
    "    # add vertices of each polygon\n",
    "    vertices = []\n",
    "    for region in regions.region:\n",
    "        vertices.append(voronoi_diagram.regions[region])\n",
    "    regions[\"vertices\"] = vertices\n",
    "\n",
    "    # convert vertices to Polygons\n",
    "    polygons = []\n",
    "    for region in tqdm(regions.vertices, desc=\"Vertices to Polygons\"):\n",
    "        if -1 not in region:\n",
    "            polygons.append(Polygon(voronoi_diagram.vertices[region]))\n",
    "        else:\n",
    "            polygons.append(None)\n",
    "    # save polygons as geometry column\n",
    "    regions[\"geometry\"] = polygons\n",
    "\n",
    "    # generate GeoDataFrame\n",
    "    regions_gdf = gpd.GeoDataFrame(regions.dropna(), geometry=\"geometry\")\n",
    "    regions_gdf = regions_gdf.loc[\n",
    "        regions_gdf[\"geometry\"].length < 1000000\n",
    "    ]  # delete errors\n",
    "    regions_gdf = regions_gdf.loc[\n",
    "        regions_gdf[unique_id] != -1\n",
    "    ]  # delete hull-based cells\n",
    "    regions_gdf.crs = crs\n",
    "    return regions_gdf\n",
    "\n",
    "\n",
    "regions_gdf = _regions(voronoi_diagram, \"uID\", ids, crs=network.crs)\n",
    "tessellation = regions_gdf[[\"uID\", \"geometry\"]].dissolve(by=\"uID\", as_index=False)\n",
    "\n",
    "\n",
    "# make linestrings\n",
    "linestrings = tessellation.geometry.exterior\n",
    "\n",
    "# clip linestrings\n",
    "# use geopandas.clip once released\n",
    "clipped = linestrings.intersection(invalid.unary_union)\n",
    "clipped = clipped[~clipped.is_empty & clipped.notnull()]\n",
    "\n",
    "clipped = clipped.reset_index(drop=True).explode().reset_index(drop=True)\n",
    "\n",
    "# split at corners\n",
    "sindex = clipped.sindex\n",
    "for ix, geom in tqdm(clipped.iteritems(), total=clipped.shape[0]):\n",
    "    corners = []\n",
    "    coords = geom.coords\n",
    "    for i in coords:\n",
    "        point = Point(i)\n",
    "        possible_matches_index = list(sindex.intersection(point.bounds))\n",
    "        possible_matches = clipped.iloc[possible_matches_index]\n",
    "        precise_matches = sum(possible_matches.intersects(point))\n",
    "        if precise_matches > 2:\n",
    "            corners.append(point)\n",
    "    if len(corners) > 1:\n",
    "        corners = MultiPoint(corners)\n",
    "        clipped.loc[ix] = shapely.ops.split(geom, corners)\n",
    "    elif len(corners) == 1:\n",
    "        clipped.loc[ix] = shapely.ops.split(geom, corners[0])\n",
    "clipped = clipped.explode().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# check duplicates shapely.ops.shared_paths\n",
    "unique = []\n",
    "for ix, line in tqdm(clipped.iteritems(), total=clipped.shape[0]):\n",
    "    if not any(l.equals(line) for l in unique):\n",
    "        unique.append(line)\n",
    "\n",
    "unique = gpd.GeoSeries(unique, crs=network.crs)\n",
    "\n",
    "\n",
    "# simplify\n",
    "unique = unique.simplify(0.5, preserve_topology=False)  # OK\n",
    "\n",
    "# fix bowties - snap\n",
    "# get snapping centroids\n",
    "centroids = _get_snapping_centroids(unique, bowtie_tolerance)\n",
    "\n",
    "# snap to centroids\n",
    "# no_false = _snap(no_false, centroids, bowtie_tolerance, min=True)\n",
    "no_false = _snap(unique, centroids, bowtie_tolerance, min=True)  # OK\n",
    "\n",
    "\n",
    "# remove unwanted lines from network. GeoPandas PR is used\n",
    "overlay = gpd.overlay(network, invalid, keep_geom_type=False, how=\"difference\")  # OK\n",
    "\n",
    "\n",
    "# remove those leading nowhere\n",
    "buffered = overlay.geometry.buffer(4)\n",
    "\n",
    "cleaned = _remove_leading_out(no_false, buffered)  # OK 1\n",
    "cleaned = mm.network_false_nodes(cleaned, precision=3)  # OK 2\n",
    "cleaned = cleaned.simplify(0.5, preserve_topology=False)  # 25\n",
    "\n",
    "# fix unprecise intersections (collapse) - snap\n",
    "# get snapping centroids\n",
    "centroids = _get_snapping_centroids(cleaned, selfsnap_tolerance)  # c1\n",
    "\n",
    "# snap to centroids\n",
    "cleaned = _snap(cleaned, centroids, selfsnap_tolerance, min=False)  # 3\n",
    "cleaned = _split(cleaned, centroids, selfsnap_tolerance).explode()  # 4 OK\n",
    "\n",
    "\n",
    "# remove those leading nowhere again = result fo snap\n",
    "cleaned = _remove_leading_out(cleaned, buffered, tolerance=0.01)  # 5  OK\n",
    "cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cleaned = mm.network_false_nodes(cleaned, precision=3)  # 6 OK\n",
    "\n",
    "cleaned = _drop_duplicates(cleaned)  # 7 OK\n",
    "\n",
    "\n",
    "# snap to network\n",
    "cleaned = _snap(cleaned, overlay.geometry, selfsnap_tolerance, min=True)  # 8 OK\n",
    "cleaned = _remove_leading_out(cleaned, overlay, tolerance=0.000001)  # 9 OK\n",
    "\n",
    "# combine together\n",
    "combined = cleaned.geometry.append(overlay.geometry).reset_index(drop=True)\n",
    "\n",
    "# merge together\n",
    "final = mm.network_false_nodes(combined, precision=3)\n",
    "print(time.time() - start, 'seconds')\n",
    "# DONE\n",
    "\n",
    "final.to_file('files/AMS/tempnet.gpkg', driver='GPKG', layer='network_simplified')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_dev",
   "language": "python",
   "name": "geo_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
